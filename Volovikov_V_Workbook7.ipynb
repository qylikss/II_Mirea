{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4e225a0a",
      "metadata": {
        "id": "4e225a0a"
      },
      "source": [
        "# –ü—Ä–∏–º–µ—Ä 1.1.1\n",
        "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–æ–≥—Ä–∞–º–º—É –æ–±—É—á–µ–Ω–∏—è –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞ –Ω–∞ —è–∑—ã–∫–µ Python. –°–Ω–∞—á–∞–ª–∞\n",
        "—Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –æ—Å–Ω–æ–≤–Ω–æ–π –∫–ª–∞—Å—Å –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–µ—Ç —É—á–∏—Ç—å—Å—è –ø–æ\n",
        "—Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8facb8b4",
      "metadata": {
        "id": "8facb8b4"
      },
      "outputs": [],
      "source": [
        "# –∫–ª–∞—Å—Å, –∫–æ—Ç–æ—Ä—ã–π —Ä–µ–∞–ª–∏–∑—É–µ—Ç –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω –∏ –µ–≥–æ –æ–±—É—á–µ–Ω–∏–µ\n",
        "class Perceptron:\n",
        "    def __init__(self, N):\n",
        "        # —Å–æ–∑–¥–∞—Ç—å –Ω—É–ª–µ–≤—ã–µ –≤–µ—Å–∞\n",
        "        self.w = list()\n",
        "        for i in range(N):\n",
        "            self.w.append( 0)\n",
        "    # –º–µ—Ç–æ–¥ –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∑–Ω–∞—á–µ–Ω–∏—è –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
        "    def calc(self, x):\n",
        "        res = 0\n",
        "        for i in range(len(self.w)):\n",
        "            res = res + self.w[i] * x[i]\n",
        "        return res\n",
        "    # –ø–æ—Ä–æ–≥–æ–≤–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
        "    def sign(self, x):\n",
        "        if self.calc(x) > 0:\n",
        "            return 1\n",
        "        else:\n",
        "            return -1\n",
        "    # –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –æ–¥–Ω–æ–º –ø—Ä–∏–º–µ—Ä–µ\n",
        "    def learn(self, la, x, y):\n",
        "        # –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ, –∫–æ–≥–¥–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ–≤–µ—Ä–Ω—ã–π\n",
        "        if y * self.calc(x) <= 0:\n",
        "            for i in range(len(self.w)):\n",
        "                self.w[i] = self.w[i] + la * y * x[i]\n",
        "    # –æ–±—É—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –¥–∞–Ω–Ω—ã–º –¢ - –∫–æ—Ä—Ç–µ–∂ –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "    def learning(self, la, T):\n",
        "        # —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è\n",
        "        for n in range(100):\n",
        "            # –æ–±—É—á–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –Ω–∞–±–æ—Ä—É –ø—Ä–∏–º–µ—Ä–æ–≤\n",
        "            for t in T:\n",
        "                self.learn(la, t[ 0], t[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7ad7b1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9b7ad7b1",
        "outputId": "6a535f57-05b3-4f84-b0a4-646557a6723c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.1, -0.1]\n",
            "-1\n",
            "1\n",
            "1\n",
            "-1\n"
          ]
        }
      ],
      "source": [
        "# —Å–æ–∑–¥–∞–µ–º –∫–ª–∞—Å—Å –¥–≤—É–º–µ—Ä–Ω–æ–≥–æ –ø–µ—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
        "perceptron = Perceptron(2)\n",
        "la = 0.1 # –∫–æ–Ω—Å—Ç–∞–Ω—Ç–∞ –æ–±—É—á–µ–Ω–∏—è\n",
        "# —Å–æ–∑–¥–∞–µ–º –ø—Ä–∏–º–µ—Ä—ã\n",
        "T = list()\n",
        "T.append([[2,1], 1])\n",
        "T.append([[3,2], 1])\n",
        "T.append([[4,1], 1])\n",
        "T.append([[1,2], -1])\n",
        "T.append([[2,3], -1])\n",
        "T.append([[5,7], -1])\n",
        "perceptron.learning(la, T) # –æ–±—É—á–µ–Ω–∏–µ –øe—Ä—Å–µ–ø—Ç—Ä–æ–Ω–∞\n",
        "print(perceptron.w) # –ø–µ—á–∞—Ç–∞–µ–º –≤–µ—Å–∞\n",
        "# –ø—Ä–æ–≤–µ—Ä–∏–º —Ä–∞–±–æ—Ç—É –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö\n",
        "print(perceptron.sign([1.5, 2]))\n",
        "print(perceptron.sign([3, 1.5]))\n",
        "print(perceptron.sign([5,1]))\n",
        "print(perceptron.sign([5,10]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdd86732",
      "metadata": {
        "id": "fdd86732"
      },
      "source": [
        "# –ü—Ä–∏–º–µ—Ä 1.1.2\n",
        "–î–ª—è –Ω–∞–ø–∏—Å–∞–Ω–∏—è –∫–æ–¥–∞ –Ω–µ–π—Ä–æ–Ω–∞ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É Pytnon\n",
        "‚Äî NumPy:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e3d93d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e3d93d5",
        "outputId": "07d204c8-8b16-4ccf-b737-ccb698871eb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9990889488055994\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "def sigmoid(x):\n",
        "    # –§—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏: f(x) = 1 / (1 + e^(-—Ö)) \n",
        "    return 1 / (1 + np.exp(-x))\n",
        "class Neuron:\n",
        "    def __init__(self, weights, bias):\n",
        "        self. weights = weights \n",
        "        self.bias = bias\n",
        "    def feedforward(self, inputs):\n",
        "        total = np.dot(self.weights, inputs) + self.bias \n",
        "        return sigmoid(total)\n",
        "\n",
        "weights = np.array([0, 1]) # w1 = 0, w2 = 1 \n",
        "bias = 4                   # c = 4 \n",
        "n = Neuron(weights, bias) \n",
        "x = np.array([2, 3])       # x = 2, y = 3 \n",
        "print(n. feedforward(x))   # 0.9990889488055994"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56e91e1b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56e91e1b",
        "outputId": "b726f654-06ac-49eb-ddf1-ce3dd575a14b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7216325609518421\n"
          ]
        }
      ],
      "source": [
        "import numpy as np \n",
        "class OurNeuralNetwork:\n",
        "    '''\n",
        "    –î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
        "        - –¥–≤–∞ –≤—Ö–æ–¥–∞ \n",
        "        - –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (h1, h2) \n",
        "        - –≤—ã—Ö–æ–¥ (o1)\n",
        "    –ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
        "        - w = [0, 1]\n",
        "        - b = 0\n",
        "    '''\n",
        "    def __init__(self):\n",
        "        weights = np.array([0, 1]) \n",
        "        bias = 0 \n",
        "        # –ö–ª–∞—Å—Å Neuron –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–≥–æ —Ä–∞–∑–¥–µ–ª–∞ \n",
        "        self.h1 = Neuron(weights, bias) \n",
        "        self.h2 = Neuron(weights, bias) \n",
        "        self.o1 = Neuron(weights, bias)\n",
        "    \n",
        "    def feedforward(self, x):\n",
        "        out_h1 = self.h1.feedforward(x) \n",
        "        out_h2 = self.h2.feedforward(x) \n",
        "        # –í—Ö–æ–¥—ã –¥–ª—è o1 - —ç—Ç–æ –≤—ã—Ö–æ–¥—ã h1 u h2 \n",
        "        out_o1 = self.o1.feedforward(np.array([out_h1, out_h2])) \n",
        "        return out_o1\n",
        "\n",
        "network = OurNeuralNetwork() \n",
        "x = np.array([2, 3]) \n",
        "print(network.feedforward(x)) # 0.7216325609518421"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dec33867",
      "metadata": {
        "id": "dec33867"
      },
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ\n",
        "–†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –ø–æ –∞–Ω–∞–ª–æ–≥–∏–∏ —Å –∫–ª–∞—Å—Å–æ–º OurNeuralNetwork. \n",
        "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
        "ÔÄ≠ —Ç—Ä–∏ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2, ùë•3);\n",
        "ÔÄ≠ —Ç—Ä–∏ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2, ‚Ñé3);\n",
        "ÔÄ≠ –≤—ã—Ö–æ–¥ (ùëú1).\n",
        "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
        "ÔÄ≠ ùë§ = [0.5, 0.5, 0.5]\n",
        "ÔÄ≠ ùëè = 0\n",
        "–î–∞–Ω–Ω—ã–µ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏:\n",
        "ÔÄ≠ –¥–≤–∞ –≤—Ö–æ–¥–∞ (ùë•1, ùë•2);\n",
        "ÔÄ≠ –¥–≤–∞ –Ω–µ–π—Ä–æ–Ω–∞ –≤ —Å–∫—Ä—ã—Ç—ã—Ö —Å–ª–æ—è—Ö (‚Ñé1, ‚Ñé2);\n",
        "ÔÄ≠ –¥–≤–∞ –≤—ã—Ö–æ–¥–∞ (ùëú1, ùëú2\n",
        ").\n",
        "–ù–µ–π—Ä–æ–Ω—ã –∏–º–µ—é—Ç –∏–¥–µ–Ω—Ç–∏—á–Ω—ã–µ –≤–µ—Å–∞ –∏ –ø–æ—Ä–æ–≥–∏:\n",
        "ÔÄ≠ ùë§ = [1, 0];\n",
        "ÔÄ≠ ùëè = 1.\n",
        "–†–µ–∞–ª–∏–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –¥—Ä—É–≥–∏—Ö —Ñ—É–Ω–∫—Ü–∏–π \n",
        "–∞–∫—Ç–∏–≤–∞—Ü–∏–∏."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed62a031",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed62a031",
        "outputId": "8448f496-308b-4b9f-8a7f-26b40a17f93f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "–ü–µ—Ä–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å\n",
            "Sigmoid:  0.8067238139969796\n",
            "Tanh:  -0.21713906537767277\n",
            "ReLU:  4.5\n",
            "\n",
            "–í—Ç–æ—Ä–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å\n",
            "Sigmoid:  (0.8757270529783324, 0.8671195555587996)\n",
            "Tanh:  (1.1555911185916798, -1.5104758308623794)\n",
            "ReLU:  (4, 5)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "def Sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "def Tanh(x):\n",
        "    return np.tan(x)\n",
        "def ReLU(x):\n",
        "    return max(0,x)\n",
        "\n",
        "class Neuron:\n",
        "    def __init__(self, w, b):\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "    def ffSigmoid(self, inputs):\n",
        "        total = np.dot(self.w, inputs) + self.b\n",
        "        return sigmoid(total)\n",
        "    def ffTanh(self, inputs):\n",
        "        total = np.dot(self.w, inputs) + self.b\n",
        "        return Tanh(total)\n",
        "    def ffReLU(self, inputs):\n",
        "        total = np.dot(self.w, inputs) + self.b\n",
        "        return ReLU(total)\n",
        "\n",
        "class NeuralNetwork1:\n",
        "    def __init__(self):\n",
        "        w = np.array([0.5, 0.5, 0.5])\n",
        "        b = 0\n",
        "        self.h1 = Neuron(w, b)\n",
        "        self.h2 = Neuron(w, b)\n",
        "        self.h3 = Neuron(w, b)\n",
        "        self.o1 = Neuron(w, b)\n",
        "    def feedforwardSigmoid(self, x):\n",
        "        out1 = self.h1.ffSigmoid(x)\n",
        "        out2 = self.h2.ffSigmoid(x)\n",
        "        out3 = self.h3.ffSigmoid(x)\n",
        "        outf = self.o1.ffSigmoid(np.array([out1, out2, out3]))\n",
        "        return outf\n",
        "    def feedforwardTanh(self, x):\n",
        "        out1 = self.h1.ffTanh(x)\n",
        "        out2 = self.h2.ffTanh(x)\n",
        "        out3 = self.h3.ffTanh(x)\n",
        "        outf = self.o1.ffTanh(np.array([out1, out2, out3]))\n",
        "        return outf\n",
        "    def feedforwardReLU(self, x):\n",
        "        out1 = self.h1.ffReLU(x)\n",
        "        out2 = self.h2.ffReLU(x)\n",
        "        out3 = self.h3.ffReLU(x)\n",
        "        outf = self.o1.ffReLU(np.array([out1, out2, out3]))\n",
        "        return outf\n",
        "    \n",
        "class NeuralNetwork2:\n",
        "    def __init__(self):\n",
        "        w = np.array([1, 0])\n",
        "        b = 1\n",
        "        self.h1 = Neuron(w, b)\n",
        "        self.h2 = Neuron(w, b)\n",
        "        self.o1 = Neuron(w, b)\n",
        "        self.o2 = Neuron(w, b)\n",
        "    def feedforwardSigmoid(self, x):\n",
        "        out1 = self.h1.ffSigmoid(x)\n",
        "        out2 = self.h2.ffSigmoid(x)\n",
        "        out1 = self.o1.ffSigmoid(np.array([out1, out2]))\n",
        "        out2 = self.o2.ffSigmoid(np.array([out1, out2]))\n",
        "        return out1, out2\n",
        "    def feedforwardTanh(self, x):\n",
        "        out1 = self.h1.ffTanh(x)\n",
        "        out2 = self.h2.ffTanh(x)\n",
        "        out1 = self.o1.ffTanh(np.array([out1, out2]))\n",
        "        out2 = self.o2.ffTanh(np.array([out1, out2]))\n",
        "        return out1, out2\n",
        "    def feedforwardReLU(self, x):\n",
        "        out1 = self.h1.ffReLU(x)\n",
        "        out2 = self.h2.ffReLU(x)\n",
        "        out1 = self.o1.ffReLU(np.array([out1, out2]))\n",
        "        out2 = self.o2.ffReLU(np.array([out1, out2]))\n",
        "        return out1, out2\n",
        "    \n",
        "network1 = NeuralNetwork1()\n",
        "x1 = np.array([1, 2, 3])\n",
        "print('–ü–µ—Ä–≤–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å')\n",
        "print('Sigmoid: ', network1.feedforwardSigmoid(x1))\n",
        "print('Tanh: ', network1.feedforwardTanh(x1))\n",
        "print('ReLU: ', network1.feedforwardReLU(x1))\n",
        "print()\n",
        "network2 = NeuralNetwork2()\n",
        "x2 = np.array([2, 3])\n",
        "print('–í—Ç–æ—Ä–∞—è –Ω–µ–π—Ä–æ—Å–µ—Ç—å')\n",
        "print('Sigmoid: ', network2.feedforwardSigmoid(x2))\n",
        "print('Tanh: ', network2.feedforwardTanh(x2))\n",
        "print('ReLU: ', network2.feedforwardReLU(x2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# –ó–∞–¥–∞–Ω–∏–µ"
      ],
      "metadata": {
        "id": "YW565as2_Snr"
      },
      "id": "YW565as2_Snr"
    },
    {
      "cell_type": "markdown",
      "id": "256301f3",
      "metadata": {
        "id": "256301f3"
      },
      "source": [
        "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –∫–ª–∞—Å—Å—ã MLPClassified –∏ MLPRegressor –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ \n",
        "—Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ –∏–Ω—Ç–µ—Ä–Ω–µ—Ç–∞. –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –∞–Ω–∞–ª–∏–∑ \n",
        "–∞—Ç—Ä–∏–±—É—Ç—ã, –ø–æ–ª—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.\n",
        "–î–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –º–æ–∂–µ—Ç–µ –≤–∑—è—Ç—å –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö –ò—Ä–∏—Å–æ–≤:\n",
        "https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\n",
        "–∞ –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –¥–∞—Ç–∞—Å–µ—Ç –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∑–∞—Ä–∞–±–æ—Ç–Ω–æ–π –ø–ª–∞—Ç—ã –æ—Ç –æ–ø—ã—Ç–∞ —Ä–∞–±–æ—Ç—ã:\n",
        "https://raw.githubusercontent.com/AnnaShestova/salary-years-simple-linear-regression/master/Salary_Data.csv "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "56ebca73",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56ebca73",
        "outputId": "30cd6c9f-d3d6-48a4-ff49-702cb48e78cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------MLPClassifier----------\n",
            "\n",
            "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3 1 4 7 0 1]\n",
            "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3 1 4 7 0 1]\n",
            "Dataset Sizes: (1797, 64) (1797,)\n",
            "Train/Test Sizes: (1437, 64) (360, 64) (1437,) (360,)\n",
            "Test Accuracy: 0.983\n",
            "Training Accuracy: 1.000\n",
            "Loss: 0.0034728684994180608\n",
            "Number of Coefs: 2\n",
            "Number of Intercepts: 2\n",
            "Number of Iterations for Which Estimator Ran: 125\n",
            "Name of Output Layer Activation Function: softmax\n",
            "\n",
            "----------MLPRegressor----------\n",
            "\n",
            "[ 5.35172001  8.03061748 11.42724672  5.98585707  1.85649195  5.31132098\n",
            "  5.46991711  9.77748793  8.10760734  7.82960361  3.82243672  2.36692296\n",
            "  0.62682947  4.50317838  3.74246433 -0.11246477  3.81734324  6.59523704\n",
            " -0.24429108  0.36959613]\n",
            "[5 9 9 6 1 6 6 9 8 7 4 2 1 4 3 1 4 7 0 1]\n",
            "Dataset Sizes: (1797, 64) (1797,)\n",
            "Train/Test Sizes: (1437, 64) (360, 64) (1437,) (360,)\n",
            "Test R^2 Score: 0.878\n",
            "Training R^2 Score: 0.983\n",
            "Loss: 0.07309221240680908\n",
            "Number of Coefs: 2\n",
            "Number of Iterations for Which Estimator Ran: 200\n",
            "Name of Output Layer Activation Function: identity\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris, load_digits\n",
        "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "print('----------MLPClassifier----------\\n')\n",
        "data = load_digits()\n",
        "X_data, Y_data = data.data, data.target\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, train_size=.80, test_size=.20, stratify=Y_data, random_state=123)\n",
        "mlp_classifier = MLPClassifier(random_state=123)\n",
        "mlp_classifier.fit(X_train, Y_train)\n",
        "Y_preds = mlp_classifier.predict(X_test)\n",
        "\n",
        "print(Y_preds[:20])\n",
        "print(Y_test[:20])\n",
        "print('Dataset Sizes:', X_data.shape, Y_data.shape)\n",
        "print('Train/Test Sizes:', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "print('Test Accuracy: %.3f'%mlp_classifier.score(X_test, Y_test))\n",
        "print('Training Accuracy: %.3f'%mlp_classifier.score(X_train, Y_train))\n",
        "print('Loss:', mlp_classifier.loss_)\n",
        "print('Number of Coefs:', len(mlp_classifier.coefs_))\n",
        "print('Number of Intercepts:', len(mlp_classifier.intercepts_))\n",
        "print('Number of Iterations for Which Estimator Ran:', mlp_classifier.n_iter_)\n",
        "print('Name of Output Layer Activation Function:', mlp_classifier.out_activation_)\n",
        "\n",
        "print('\\n----------MLPRegressor----------\\n')\n",
        "data = load_digits()\n",
        "X_data, Y_data = data.data, data.target\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X_data, Y_data, train_size=.80, test_size=.20, stratify=Y_data, random_state=123)\n",
        "mlp_regressor = MLPRegressor(random_state=123)\n",
        "mlp_regressor.fit(X_train, Y_train)\n",
        "Y_preds = mlp_regressor.predict(X_test)\n",
        "\n",
        "print(Y_preds[:20])\n",
        "print(Y_test[:20])\n",
        "print('Dataset Sizes:', X_data.shape, Y_data.shape)\n",
        "print('Train/Test Sizes:', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "print('Test R^2 Score: %.3f'%mlp_regressor.score(X_test, Y_test))\n",
        "print('Training R^2 Score: %.3f'%mlp_regressor.score(X_train, Y_train))\n",
        "print('Loss:', mlp_regressor.loss_)\n",
        "print('Number of Coefs:', len(mlp_regressor.coefs_))\n",
        "print('Number of Iterations for Which Estimator Ran:', mlp_regressor.n_iter_)\n",
        "print('Name of Output Layer Activation Function:', mlp_regressor.out_activation_)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}